HW6
================
Serena (sjt2164)

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

## Problem 1

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

    ## using cached file: /Users/serenating/Library/Caches/org.R-project.R/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2024-10-27 21:40:52.853389 (8.656)

    ## file min/max dates: 1869-01-01 / 2024-10-31

*Prompt*

- `tmax` as the response

- `tmin` as the predictor

- interested in distribution of two quantities estimated from:

  - 𝑟̂ 2
  - log(𝛽̂ 0∗𝛽̂ 1)

- Use 5000 bootstrap samples

- For each bootstrap sample, produce estimates of these two quantities.

- Plot the distribution of your estimates, and describe these in words.

- Using the 5000 bootstrap estimates, identify the 2.5% and 97.5%
  quantiles to provide a 95% confidence interval for 𝑟̂ 2 and log(𝛽̂ 0∗𝛽̂
  1)

- Use broom::glance() for extracting 𝑟̂ 2 from a fitted regression

- Use broom::tidy() (with some additional wrangling) to compute log(𝛽̂
  0∗𝛽̂ 1)

## Problem 2: Homicides in 50 large U.S. cities

``` r
#Import from github repo, read article.
```

- Create a `city_state` variable (e.g. “Baltimore, MD”), and a binary
  variable indicating whether the homicide is solved (ex. `solved`: y/n)

- Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO (they don’t
  report victim race)

- Omit Tulsa, AL (is a data entry mistake)

- Limit your analysis to those for whom `victim_race` is `white` or
  `black`.

- Be sure that `victim_age` is numeric.

\_\**Baltimore, MD*

- For the city of Baltimore, MD, use the `glm` function to fit a
  logistic regression with resolved vs unresolved as the outcome and
  victim age, sex and race as predictors.
- Save output of `glm` as an R object; apply the `broom::tidy` to this
  object
- Obtain the estimate and confidence interval of the adjusted odds ratio
  for solving homicides comparing male victims to female victims keeping
  all other variables fixed.

*Glm for the Cities*

- Now run glm for each of the cities in your dataset
- Extract the adjusted odds ratio (and CI) for solving homicides
  comparing male victims to female victims.
- Do this within a “tidy” pipeline, making use of `purrr::map`, list
  columns, and `unnest` as necessary to create a dataframe with
  estimated ORs and CIs for each city.

*Plot*

- Shows the estimated ORs and CIs for each city on plot
- Organize cities according to estimated OR
- Comment on the plot

## Problem 3: Effects of variables on a child’s birthweight

``` r
bwt_df = read_csv("./data/birthweight.csv", na = c("NA", ".", ""))
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Dataset has ~4000 children and includes the following variables:

- `babysex`: baby’s sex (male = 1, female = 2)
- `bhead`: baby’s head circumference at birth (centimeters)
- `blength`: baby’s length at birth (centimeteres)
- `bwt`: baby’s birth weight (grams)
- `delwt`: mother’s weight at delivery (pounds)
- `fincome`: family monthly income (in hundreds, rounded)
- `frace`: father’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto
  Rican, 8 = Other, 9 = Unknown)
- `gaweeks`: gestational age in weeks
- `malform`: presence of malformations that could affect weight (0 =
  absent, 1 = present)
- `menarche`: mother’s age at menarche (years)
- `mheigth`: mother’s height (inches)
- `momage`: mother’s age at delivery (years)
- `mrace`: mother’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto
  Rican, 8 = Other)
- `parity`: number of live births prior to this pregnancy
- `pnumlbw`: previous number of low birth weight babies
- `pnumgsa`: number of prior small for gestational age babies
- `ppbmi`: mother’s pre-pregnancy BMI
- `ppwt`: mother’s pre-pregnancy weight (pounds)
- `smoken`: average number of cigarettes smoked per day during pregnancy
- wtgain\`: mother’s weight gain during pregnancy (pounds)

#### Data Cleaning

``` r
#clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).
```

#### Regression Model

Propose a regression model for birthweight. \* Model may be based on a
hypothesized structure for the factors that underly birthweight, on a
data-driven model-building process, or a combination of the two. \*
Describe modeling process

- Show a plot of model residuals against fitted values – use
  `add_predictions` and `add_residuals` in making this plot.

#### Compare your model to two others:

- One using length at birth and gestational age as predictors (main
  effects only)

- One using head circumference, length, sex, and all interactions
  (including the three-way interaction) between these

Make this comparison in terms of the cross-validated prediction error;
use `crossv_mc` and functions in `purrr` as appropriate.

Note that although we expect your model to be reasonable, model building
itself is not a main idea of the course and we don’t necessarily expect
your model to be “optimal”.
